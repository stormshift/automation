---
  - name: Create MicroShift VM "{{ ushift_virt_namespace }}/{{ inventory_hostname }}"
    tags: vm
    throttle: 4
    local_action:
      module: kubevirt.core.kubevirt_vm
      api_key:         "{{ hostvars['isar']['k8s_auth_api_key'] }}"
      host:            "{{ hostvars['isar']['k8s_auth_host'] }}"
      validate_certs:  "{{ hostvars['isar']['k8s_auth_verify_ssl'] }}"
      state: present
      runStrategy: "{{ ocpVirt_runStrategy_running }}" # default
      wait: true
      wait_timeout: 480
      name: "{{ inventory_hostname }}"
      labels:
        vm_group: "{{ group_names[0] }}"
      annotations:
        descheduler.alpha.kubernetes.io/evict: "{{ descheduler_evict }}"
      namespace: "{{ ushift_virt_namespace }}"
      spec:
# We want to be co-located with img bld where the ostree-commits
# are being served from, and we make this required because imgbld
# has to run for this demo to work:
        # affinity:
        #   podAffinity:
        #     requiredDuringSchedulingIgnoredDuringExecution:
        #     - labelSelector:
        #         matchExpressions:
        #         - key: vm.kubevirt.io/name
        #           operator: In
        #           values:
        #           - ushift-imgbld
        #       topologyKey: kubernetes.io/hostname
# For larger fleets, we want to have anti-affinity to distribute across nodes, to better leverage
# network resource:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: vm_group
                    operator: In
                    values:
                    - "{{ group_names[0] }}"
                topologyKey: kubernetes.io/hostname
        domain:
          cpu:
            cores: "{{ vm_cores }}"
            sockets: 1
            threads: 1
          memory:
            guest: "{{vm_memory}}"
          resources:
            requests:
              memory: "{{vm_memory}}"
              cpu: "{{ vm_cores*1000 * 0.5}}m"
          features:
            acpi: {}
            smm:
              enabled: true
          firmware:
            bootloader:
              efi:
                secureBoot: false
                persistent: true
#            kernelBoot:
#              kernelArgs: --- test me later ---
          machine:
            type: q35
          devices:
            disks:
            - disk:
                bus: virtio
              name: root-disk
              bootOrder: 1
            interfaces:
              - bridge: {}
                macAddress: "{{network_mac_address}}"
                model: virtio
                name: net-0
                bootOrder: 2
            tpm:
              persistent: true
          clock:
            timezone: Etc/GMT
        networks:
          - multus:
              networkName: coe-bridge
            name: net-0
        volumes:
        - dataVolume:
            name: "{{ inventory_hostname }}-root"
          name: root-disk
      data_volume_templates:
        - metadata:
            name: "{{ inventory_hostname }}-root"
          spec:
            storage:
              storageClassName: "{{ushift_vm_storageclass}}"
              accessModes:
              - ReadWriteMany
              volumeMode: Block
              resources:
                requests:
                  storage: "{{ vm_disk }}"
            source:
              blank: {}

  - name: Wait for VM to be online
    local_action:
      module: ansible.builtin.wait_for
      host: "{{ inventory_hostname }}.{{ sysctx_dns_domain }}"
      port: 22
      state: started
      sleep: 2
      timeout: 1200

  - name: Wait for MicroShift to be online
    local_action:
      module: ansible.builtin.wait_for
      host: "{{ inventory_hostname }}.{{ sysctx_dns_domain }}"
      port: 443
      state: started
      sleep: 2
      timeout: 300
